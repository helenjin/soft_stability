{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15db50f4-92ab-4071-9ac9-790a5643c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as tvtfs\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import datasets as hfds\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor, get_scheduler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "261bb8dc-7449-4f4a-b4a7-6a400f7cd05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name_or_path: str = \"google/vit-base-patch16-224\"):\n",
    "    return ViTForImageClassification.from_pretrained(model_name_or_path, num_labels=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ec97274-d5c5-421f-bdc9-8c82419ce947",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagenetDataset(Dataset):\n",
    "    \"\"\" Imagenet dataset with random masking \"\"\"\n",
    "    def __init__(self, split: str, rand_masks: bool = False):\n",
    "        self.split = split\n",
    "        self.ds = hfds.load_dataset(\"ILSVRC/imagenet-1k\", split=split, cache_dir=\"/shared_data0/antonxue/\")\n",
    "        self.processor = ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "        self.rand_masks = rand_masks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "        image = item[\"image\"]\n",
    "        image = self.processor(\n",
    "            image if image.mode == \"RGB\" else image.convert(\"RGB\"),\n",
    "            return_tensors = \"pt\",\n",
    "        )[\"pixel_values\"].view(3,224,224)\n",
    "        # Each 16x16 patch (14x14 grid) has a random chance of turning off, randomly.\n",
    "        if self.rand_masks:\n",
    "            small_mask = torch.rand(1,1,14,14) < torch.rand(())\n",
    "            large_mask = F.interpolate(small_mask.float(), scale_factor=(16,16))\n",
    "            image = image.view(3,224,224) * large_mask.view(1,224,224)\n",
    "        return {\"image\": image, \"label\": item[\"label\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93715c32-c9ab-4d7b-8fae-66432e811e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/datasets/load.py:1491: FutureWarning: The repository for ILSVRC/imagenet-1k contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/ILSVRC/imagenet-1k\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a1c0e8921ba462982540ae8f92d4707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/257 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1281167"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ImagenetDataset(split=\"train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dac16f81-abaf-4196-8d05-aa7738901988",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/datasets/load.py:1491: FutureWarning: The repository for ILSVRC/imagenet-1k contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/ILSVRC/imagenet-1k\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5e6061e12a04394b4241182e7215aba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ImagenetDataset(split=\"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a655d3-c23b-4da3-bf97-59c99a8e534d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7c59ea1-a894-443d-8c72-1d99547799c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, optimizer, lr_scheduler):\n",
    "    model.train()\n",
    "    device = next(model.parameters()).device\n",
    "    all_losses, all_accs = [], []\n",
    "    pbar = tqdm(dataloader)\n",
    "    for batch in pbar:\n",
    "        image, label = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
    "        logits = model(image).logits\n",
    "        loss = F.cross_entropy(logits, label)\n",
    "        loss.backward(); optimizer.step(); optimizer.zero_grad(); lr_scheduler.step()\n",
    "\n",
    "        all_losses.append(loss.detach().item())\n",
    "        all_accs.append((logits.argmax(dim=-1) == label).float().mean().detach().item())\n",
    "        pbar.set_description(\n",
    "            f\"lr {lr_scheduler.get_last_lr()[0]:.3e}, \"\n",
    "            + f\"loss {torch.tensor(all_losses[-16:]).mean():.3e}, \"\n",
    "            + f\"acc {torch.tensor(all_accs[-16:]).float().mean():.3e}\"\n",
    "        )\n",
    "    return {\"state_dict\": model.state_dict(), \"train_losses\": all_losses, \"train_accs\": all_accs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d68e4f3c-cb28-44a0-a46f-81bfbfa6f4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, dataloader):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    all_losses, all_accs = [], []\n",
    "    pbar = tqdm(dataloader)\n",
    "    for batch in pbar:\n",
    "        image, label = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
    "        logits = model(image).logits\n",
    "        loss = F.cross_entropy(logits, label)\n",
    "\n",
    "        all_losses.append(loss.detach().item())\n",
    "        all_accs.append((logits.argmax(dim=-1) == label).float().mean().detach().item())\n",
    "        pbar.set_description(\n",
    "            f\"loss {torch.tensor(all_losses[-16:]).mean():.3e}, \"\n",
    "            + f\"acc {torch.tensor(all_accs[-16:]).float().mean():.3e}\"\n",
    "        )\n",
    "    return {\"valid_losses\": all_losses, \"valid_accs\": all_accs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e260db02-fb61-4d05-abb5-48b8a28af3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_finetuning_epochs(\n",
    "    num_epochs: int = 5,\n",
    "    bsz: int = 128,\n",
    "    lr: float = 1e-4,\n",
    "    device: str = \"cuda\",\n",
    "    saveto_dir: str = \"../_saved_models\",\n",
    "):\n",
    "    # Make directory if doesn't exist\n",
    "    Path(saveto_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Initialize dataloaders\n",
    "    train_dataloader = DataLoader(ImagenetDataset(\"train\", rand_masks=True), batch_size=bsz, num_workers=24, shuffle=True)\n",
    "    valid_dataloader = DataLoader(ImagenetDataset(\"validation\", rand_masks=True), batch_size=bsz, num_workers=24, shuffle=True)\n",
    "\n",
    "    # Set up the model, optimizer, and learning rate scheduler\n",
    "    model = load_model()\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    num_train_steps = len(train_dataloader) * num_epochs\n",
    "    lr_scheduler = get_scheduler(\n",
    "        name = \"linear\",\n",
    "        optimizer = optimizer,\n",
    "        num_warmup_steps = int(0.1 * num_train_steps),\n",
    "        num_training_steps = num_train_steps\n",
    "    )\n",
    "\n",
    "    # Fine-tuning loop\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        saveto = f\"{saveto_dir}/google_vit_patch16_img224_bsz{bsz}_lr{lr:.4f}_epoch{epoch}.pt\" \n",
    "        print(\"Training\", saveto)\n",
    "        train_ret = train_one_epoch(model, train_dataloader, optimizer, lr_scheduler)\n",
    "        valid_ret = valid_one_epoch(model, valid_dataloader)\n",
    "        train_ret[\"valid_losses\"] = valid_ret[\"valid_losses\"]\n",
    "        train_ret[\"valid_accs\"] = valid_ret[\"valid_accs\"]\n",
    "        torch.save(train_ret, saveto)\n",
    "\n",
    "    return train_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d18c6bc-d359-4872-bea3-0b4e69e8b7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c521b62bf874316add177abdf38b849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/257 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ../_saved_models/google_vit_patch16_img224_bsz128_lr0.0001_epoch1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lr 7.592e-07, loss 1.996e+00, acc 6.162e-01:   0%|                                | 38/10010 [03:02<2:57:59,  1.07s/it]/opt/conda/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:648: UserWarning: Metadata Warning, tag 274 had too many entries: 4, expected 1\n",
      "  warnings.warn(\n",
      "lr 2.402e-05, loss 1.154e+00, acc 7.280e-01:  12%|███▎                        | 1202/10010 [1:12:39<2:57:33,  1.21s/it]/opt/conda/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:866: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "lr 4.230e-05, loss 1.172e+00, acc 7.373e-01:  21%|█████▉                      | 2117/10010 [1:58:02<1:55:36,  1.14it/s]/opt/conda/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:866: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "lr 6.048e-05, loss 1.246e+00, acc 7.212e-01:  30%|████████▍                   | 3027/10010 [2:45:58<2:20:26,  1.21s/it]/opt/conda/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:866: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "lr 6.210e-05, loss 1.139e+00, acc 7.393e-01:  31%|████████▋                   | 3108/10010 [2:49:32<2:36:10,  1.36s/it]/opt/conda/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:866: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "lr 7.351e-05, loss 1.314e+00, acc 7.104e-01:  37%|██████████▎                 | 3679/10010 [3:14:04<1:48:47,  1.03s/it]/opt/conda/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:866: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "lr 7.666e-05, loss 1.146e+00, acc 7.280e-01:  38%|██████████▋                 | 3837/10010 [3:21:13<8:53:06,  5.18s/it]/opt/conda/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:866: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "lr 8.382e-05, loss 1.225e+00, acc 7.188e-01:  42%|███████████▋                | 4195/10010 [3:33:44<1:36:46,  1.00it/s]/opt/conda/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:866: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "lr 9.305e-05, loss 1.184e+00, acc 7.207e-01:  47%|█████████████               | 4657/10010 [3:45:33<2:31:10,  1.69s/it]/opt/conda/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:648: UserWarning: Metadata Warning, tag 274 had too many entries: 4, expected 1\n",
      "  warnings.warn(\n",
      "lr 9.876e-05, loss 1.216e+00, acc 7.139e-01:  49%|█████████████▊              | 4943/10010 [3:53:39<2:27:38,  1.75s/it]/opt/conda/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:866: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "lr 9.925e-05, loss 1.175e+00, acc 7.153e-01:  53%|██████████████▉             | 5343/10010 [4:03:41<1:11:02,  1.09it/s]/opt/conda/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:866: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "lr 9.901e-05, loss 1.277e+00, acc 6.973e-01:  54%|███████████████▎            | 5453/10010 [4:05:45<1:17:36,  1.02s/it]"
     ]
    }
   ],
   "source": [
    "run_finetuning_epochs(num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4925461-7d12-4624-a91a-7fa8c0057a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
